{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f7544f-4a4f-4443-ba02-1119e04ee105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datacube import Datacube\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import pystac_client\n",
    "import odc.stac\n",
    "import timeit\n",
    "import pstats\n",
    "import cProfile\n",
    "sys.path.insert(1, \"../Tools/\")\n",
    "from dea_tools.plotting import rgb\n",
    "odc.stac.configure_rio(\n",
    "    cloud_defaults=True,\n",
    "    aws={\"aws_unsigned\": True},\n",
    ")\n",
    "stac_prod = pystac_client.Client.open(\"https://explorer.dea.ga.gov.au/stac\")\n",
    "stac_dev = pystac_client.Client.open(\"https://explorer.dev.dea.ga.gov.au/stac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0983589-d755-463c-aecf-bebdaad8334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dc_dev = Datacube(app='', env='dev')\n",
    "#dc_prod = Datacube(app='')\n",
    "time_range = ['2024-04-01', '2025-07-01']\n",
    "time_to_drill = (\"2025-01\", \"2025-03\")\n",
    "\n",
    "# Set a start and end date\n",
    "start_date = \"2025-03-01\"\n",
    "end_date = \"2025-03-31\"\n",
    "\n",
    "# Set product ID as the STAC \"collection\"\n",
    "collections = [\"ga_ls9c_ard_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c11fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f80b016-e522-4063-9045-57b3d7d46a80",
   "metadata": {},
   "source": [
    "## ARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52ee9f-3304-46b7-a4eb-2e1d24178899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "869\n",
      "https://explorer.dea.ga.gov.au/stac/collections/ga_ls9c_ard_3/items/4eb8a67a-877f-4a0f-aa61-f239636f3f1f\n",
      "<built-in method title of str object at 0x7560abdc68d0>\n",
      "869\n",
      "{'type': 'Catalog', 'numberReturned': 867, 'numberMatched': 861}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.12/site-packages/pystac_client/client.py:191: NoConformsTo: Server does not advertise any conformance classes.\n",
      "  warnings.warn(NoConformsTo())\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    'time': ('2025-01-01', '2025-09-06'),\n",
    "    'product':'ga_ls9c_ard_3',\n",
    "}\n",
    "# dev_ards=dc_dev.find_datasets(**query)\n",
    "#prod_ards=dc_prod.find_datasets(**query)\n",
    "# ids_dev = [str(dsdev.id) for dsdev in dev_ards]\n",
    "#ids_prod = [str(dsprod.id) for dsprod in prod_ards]\n",
    "# print(len(ids_dev))\n",
    "#print(len(ids_prod))\n",
    "# print(ids_dev[:10])\n",
    "#print(ids_prod[:10])\n",
    "#dev_ard_ls8 = dc_dev.find_datasets(product='ga_ls8c_ard_3', time=time_range)\n",
    "#dev_ard_ls9 = dc_dev.find_datasets(product='ga_ls9c_ard_3', time=time_range)\n",
    "#dev_ard_all = dev_ard_ls8 #+ dev_ard_ls9\n",
    "# dev_ards = stac_prod.search(\n",
    "#     collections=collections,\n",
    "#     datetime=f\"{start_date}/{end_date}\",    \n",
    "# )\n",
    "stac_prod = pystac_client.Client.open(\"https://explorer.dea.ga.gov.au/stac\")\n",
    "\n",
    "\n",
    "ga_ls9c_ard_3_aug25_catalog = pystac_client.Client.open(\"https://explorer.dea.ga.gov.au/stac/catalogs/ga_ls9c_ard_3/2025-8?limit=999\")\n",
    "print(len(ga_ls9c_ard_3_aug25_catalog.get_links()))\n",
    "ga_ls9c_ard_3_aug25_datasets = list(ga_ls9c_ard_3_aug25_catalog.get_links())\n",
    "print(ga_ls9c_ard_3_aug25_datasets[3].get_target_str())\n",
    "print(ga_ls9c_ard_3_lnks[3].title)\n",
    "print(len(ga_ls9c_ard_3_aug25_datasets))\n",
    "print(ga_ls9c_ard_3_aug25_catalog.extra_fields)\n",
    "\n",
    "start_date = \"2025-03-01\"\n",
    "end_date = \"2025-03-31\"\n",
    "collections = [\"ga_ls9c_ard_3\"]\n",
    "\n",
    "# collections = list(stac_prod.get_collections())\n",
    "# print(f\"Number of collections: {len(collections)}\")\n",
    "# print(\"Collections IDs:\")\n",
    "# for collection in collections:\n",
    "#     print(f\"- {collection.id}\")\n",
    "\n",
    "# execution_time = timeit.timeit(prod_stac_function, number=1)\n",
    "# print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "collection = stac_prod.get_child(\"ga_ls9c_ard_3\")\n",
    "ard_collection = stac_prod.get_collection(\"ga_ls9c_ard_3\")\n",
    "print(f\"Collection ID: {collection.id}\")\n",
    "print(f\"Title: {collection.title}\")\n",
    "print(f\"Description: {collection.description}\")\n",
    "# print(collection.get_item_links())\n",
    "# for i in stac_prod.get_items(recursive=True):\n",
    "#     print(i.id)\n",
    "def prod_stac_function():\n",
    "    prod_ards = stac_prod.search(\n",
    "        collections=collections,\n",
    "        datetime=f\"{start_date}/{end_date}\", \n",
    "        fields={\"include\": [\"ids\"]},\n",
    "        #max_items=1,\n",
    "        limit=100,    \n",
    "    )\n",
    "    items_prod=list(prod_ards.items())\n",
    "    ids_prod = [str(dsprod.id) for dsprod in items_prod]\n",
    "    print(prod_ards.matched())\n",
    "    # print(ids_dev[:10])\n",
    "    print(ids_prod[:1])\n",
    "    # for item in prod_ards.items():\n",
    "    #     print(item.id)\n",
    "\n",
    "# execution_time = timeit.timeit(prod_stac_function(), number=1)\n",
    "# print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "\n",
    "cProfile.runctx(\"prod_stac_function()\",None, locals(),'my_func_stats')\n",
    "\n",
    "p = pstats.Stats(\"my_func_stats\")\n",
    "p.sort_stats(\"cumulative\").print_stats()\n",
    "# Search the STAC catalog for all items matching the query\n",
    "#ids_dev=list(dev_ards)      \n",
    "#ids_prod=list(prod_ards)\n",
    "#prod_ard_ls8 = dc_prod.find_datasets(product='ga_ls8c_ard_3', time=time_range)\n",
    "#prod_ard_ls9 = dc_prod.find_datasets(product='ga_ls9c_ard_3', time=time_range)\n",
    "#prod_ard_all = prod_ard_ls8 #+ prod_ard_ls9\n",
    "# dev_items = list(dev_ards.items())\n",
    "# prod_items = list(prod_ards.items())\n",
    "# print(f\"Found: {len(dev_items):d} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c4101-05f8-41b8-8aed-1886094e462d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prod_ard_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# get only final maturity\u001b[39;00m\n\u001b[32m      2\u001b[39m final_prod_ard = [\n\u001b[32m      3\u001b[39m     ds\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m \u001b[43mprod_ard_all\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ds.metadata_doc.get(\u001b[33m\"\u001b[39m\u001b[33mproperties\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\u001b[33m\"\u001b[39m\u001b[33mdea:dataset_maturity\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[33m\"\u001b[39m\u001b[33mfinal\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m ]\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# count unique IDs by path and row\u001b[39;00m\n\u001b[32m      9\u001b[39m ard_path_row_unique_ids = {}\n",
      "\u001b[31mNameError\u001b[39m: name 'prod_ard_all' is not defined"
     ]
    }
   ],
   "source": [
    "# get only final maturity\n",
    "final_prod_ard = [\n",
    "    ds\n",
    "    for ds in prod_ard_all\n",
    "    if ds.metadata_doc.get(\"properties\", {}).get(\"dea:dataset_maturity\") == \"final\"\n",
    "]\n",
    "\n",
    "# count unique IDs by path and row\n",
    "ard_path_row_unique_ids = {}\n",
    "\n",
    "for ds in final_prod_ard:\n",
    "    props = ds.metadata_doc.get(\"properties\", {})\n",
    "    path = props.get(\"landsat:wrs_path\")\n",
    "    row = props.get(\"landsat:wrs_row\")\n",
    "    unique_id = ds.metadata_doc.get(\"id\")  # Use the UUID as unique scene identifier\n",
    "    if path is None or row is None or unique_id is None:\n",
    "        continue\n",
    "    key = (path, row)\n",
    "    if key not in ard_path_row_unique_ids:\n",
    "        ard_path_row_unique_ids[key] = set()\n",
    "    ard_path_row_unique_ids[key].add(unique_id)\n",
    "ard_path_row_unique_ids\n",
    "# Now build DataFrame with counts of unique scene IDs\n",
    "df = pd.DataFrame(\n",
    "    [{\"path\": k[0], \"row\": k[1], \"count\": len(v)} for k, v in ard_path_row_unique_ids.items()]\n",
    ")\n",
    "pivot_df = df.pivot(index=\"row\", columns=\"path\", values=\"count\")\n",
    "# mirror columns to match order of scenes\n",
    "pivot_df = pivot_df[pivot_df.columns[::-1]]\n",
    "\n",
    "pivot_df.index.name = \"\"\n",
    "pivot_df.columns.name = \"\"\n",
    "\n",
    "pivot_df.to_csv(\"ARD_prod_ls8ls9_count_final_uniqueid.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c12175-525f-4c95-8465-0b38435bb792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only final maturity\n",
    "final_dev_ard = [\n",
    "    ds\n",
    "    for ds in dev_ard_all\n",
    "    if ds.metadata_doc.get(\"properties\", {}).get(\"dea:dataset_maturity\") == \"final\"\n",
    "]\n",
    "\n",
    "# count unique IDs by path and row\n",
    "ard_path_row_unique_ids = {}\n",
    "\n",
    "for ds in final_dev_ard:\n",
    "    props = ds.metadata_doc.get(\"properties\", {})\n",
    "    path = props.get(\"landsat:wrs_path\")\n",
    "    row = props.get(\"landsat:wrs_row\")\n",
    "    unique_id = ds.metadata_doc.get(\"id\")  # Use the UUID as unique scene identifier\n",
    "    if path is None or row is None or unique_id is None:\n",
    "        continue\n",
    "    key = (path, row)\n",
    "    if key not in ard_path_row_unique_ids:\n",
    "        ard_path_row_unique_ids[key] = set()\n",
    "    ard_path_row_unique_ids[key].add(unique_id)\n",
    "\n",
    "# Now build DataFrame with counts of unique scene IDs\n",
    "df = pd.DataFrame(\n",
    "    [{\"path\": k[0], \"row\": k[1], \"count\": len(v)} for k, v in ard_path_row_unique_ids.items()]\n",
    ")\n",
    "pivot_df = df.pivot(index=\"row\", columns=\"path\", values=\"count\")\n",
    "# mirror columns to match order of scenes\n",
    "pivot_df = pivot_df[pivot_df.columns[::-1]]\n",
    "\n",
    "pivot_df.index.name = \"\"\n",
    "pivot_df.columns.name = \"\"\n",
    "\n",
    "pivot_df.to_csv(\"ARD_dev_ls8ls9_count_final_uniqueid.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207863eb-970b-4c71-836d-dc38940c325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_count = pd.read_csv('ARD_prod_ls8ls9_count_final_uniqueid.csv', index_col=0)\n",
    "dev_count = pd.read_csv('ARD_dev_ls8ls9_count_final_uniqueid.csv', index_col=0)\n",
    "\n",
    "# reduce to columns in common\n",
    "prod_count = prod_count[[c for c in prod_count.columns if c in dev_count.columns]]\n",
    "dev_count = dev_count[[c for c in prod_count.columns]]\n",
    "\n",
    "# reduce to same index \n",
    "common_index = prod_count.index.intersection(dev_count.index)\n",
    "prod_count = prod_count.loc[common_index]\n",
    "dev_count = dev_count.loc[common_index]\n",
    "\n",
    "# double check\n",
    "assert prod_count.columns.equals(dev_count.columns)\n",
    "assert prod_count.index.equals(dev_count.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e454a-db08-4aaf-aeb8-d408bbde5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = prod_count - dev_count\n",
    "diff.to_csv('diff_dev_prod_count_unique_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19114625-26d1-47b0-9718-df95bb48583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# use the existing diff DataFrame as starting point\n",
    "diff_df = pd.read_csv('diff_dev_prod_count_unique_final.csv', index_col=0)\n",
    "\n",
    "# heatmap without cell annotations\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    diff_df,\n",
    "    fmt='',\n",
    "    cmap='YlOrRd',\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray',\n",
    "    square=True,\n",
    "    cbar_kws={'label': 'Missing Scenes Count'},\n",
    "    vmin=0,\n",
    "    # vmax=2\n",
    ")\n",
    "\n",
    "ax.set_title('LS8 + LS9 ARD: Prod - Dev', fontsize=14)\n",
    "ax.set_xlabel('Path')\n",
    "ax.set_ylabel('Row')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef6ffc-d686-4ba9-a73d-b0ad9e8ad2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b917b2-692a-4582-96d8-3a2a2d1df25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac954b35-134b-44ac-a868-d968962731c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_wofs = dc_dev.find_datasets(product='ga_ls_wo_3', time=time_range)\n",
    "\n",
    "dev_wofs = dc_dev.find_datasets(product='ga_ls_wo_3', time=time_range)\n",
    "\n",
    "prod_wofs = dc_prod.find_datasets(product='ga_ls_wo_3', time=time_range)\n",
    "c = list(set(prod_wofs) - set(dev_wofs))\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67cb54-0056-471a-beac-05fd9b6603b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for final maturity only\n",
    "final_dev_wofs = [\n",
    "    ds\n",
    "    for ds in dev_wofs\n",
    "    if ds.metadata_doc.get(\"properties\", {}).get(\"dea:dataset_maturity\") == \"final\"\n",
    "]\n",
    "\n",
    "# Count unique scene IDs by path and row\n",
    "wofs_path_row_unique_ids = {}\n",
    "\n",
    "for ds in final_dev_wofs:\n",
    "    props = ds.metadata_doc.get(\"properties\", {})\n",
    "    path = props.get(\"landsat:wrs_path\")\n",
    "    row = props.get(\"landsat:wrs_row\")\n",
    "    unique_id = ds.metadata_doc.get(\"id\")  # UUID as the unique identifier\n",
    "    if path is None or row is None or unique_id is None:\n",
    "        continue\n",
    "    key = (path, row)\n",
    "    if key not in wofs_path_row_unique_ids:\n",
    "        wofs_path_row_unique_ids[key] = set()\n",
    "    wofs_path_row_unique_ids[key].add(unique_id)\n",
    "dev_wofs_path_row_unique_ids=wofs_path_row_unique_ids\n",
    "# Create DataFrame with counts\n",
    "df = pd.DataFrame(\n",
    "    [{\"path\": k[0], \"row\": k[1], \"count\": len(v)} for k, v in wofs_path_row_unique_ids.items()]\n",
    ")\n",
    "\n",
    "pivot_df = df.pivot(index=\"row\", columns=\"path\", values=\"count\")\n",
    "\n",
    "# Reverse columns (if needed)\n",
    "pivot_df = pivot_df[pivot_df.columns[::-1]]\n",
    "\n",
    "# Clean up axis labels\n",
    "pivot_df.index.name = \"\"\n",
    "pivot_df.columns.name = \"\"\n",
    "\n",
    "# Export to CSV\n",
    "pivot_df.to_csv(\"wofs_dev_count_final_uniqueid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5b852-220f-40f3-be46-b278b35bd626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for final maturity only\n",
    "final_prod_wofs = [\n",
    "    ds\n",
    "    for ds in prod_wofs\n",
    "    if ds.metadata_doc.get(\"properties\", {}).get(\"dea:dataset_maturity\") == \"final\"\n",
    "]\n",
    "\n",
    "# Count unique scene IDs by path and row\n",
    "wofs_path_row_unique_ids = {}\n",
    "\n",
    "for ds in final_prod_wofs:\n",
    "    props = ds.metadata_doc.get(\"properties\", {})\n",
    "    path = props.get(\"landsat:wrs_path\")\n",
    "    row = props.get(\"landsat:wrs_row\")\n",
    "    unique_id = ds.metadata_doc.get(\"id\")  # UUID as the unique identifier\n",
    "    if path is None or row is None or unique_id is None:\n",
    "        continue\n",
    "    key = (path, row)\n",
    "    if key not in wofs_path_row_unique_ids:\n",
    "        wofs_path_row_unique_ids[key] = set()\n",
    "    wofs_path_row_unique_ids[key].add(unique_id)\n",
    "prod_wofs_path_row_unique_ids=wofs_path_row_unique_ids\n",
    "# Create DataFrame with counts\n",
    "df = pd.DataFrame(\n",
    "    [{\"path\": k[0], \"row\": k[1], \"count\": len(v)} for k, v in wofs_path_row_unique_ids.items()]\n",
    ")\n",
    "\n",
    "pivot_df = df.pivot(index=\"row\", columns=\"path\", values=\"count\")\n",
    "\n",
    "# Reverse columns (if needed)\n",
    "pivot_df = pivot_df[pivot_df.columns[::-1]]\n",
    "\n",
    "# Clean up axis labels\n",
    "pivot_df.index.name = \"\"\n",
    "pivot_df.columns.name = \"\"\n",
    "\n",
    "# Export to CSV\n",
    "pivot_df.to_csv(\"wofs_prod_count_final_uniqueid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31ee27-101f-4a57-bf75-f1870eb08792",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_count = pd.read_csv('wofs_prod_count_final_uniqueid.csv', index_col=0)\n",
    "dev_count = pd.read_csv('wofs_dev_count_final_uniqueid.csv', index_col=0)\n",
    "\n",
    "# reduce to columns in common\n",
    "prod_count = prod_count[[c for c in prod_count.columns if c in dev_count.columns]]\n",
    "dev_count = dev_count[[c for c in prod_count.columns]]\n",
    "\n",
    "# reduce to same index \n",
    "common_index = prod_count.index.intersection(dev_count.index)\n",
    "prod_count = prod_count.loc[common_index]\n",
    "dev_count = dev_count.loc[common_index]\n",
    "\n",
    "# double check\n",
    "assert prod_count.columns.equals(dev_count.columns)\n",
    "assert prod_count.index.equals(dev_count.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cebe9b-6335-4b8f-a2f3-179d245b2e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = prod_count - dev_count\n",
    "diff.to_csv('wo_diff_dev_prod_count_final_uniqueid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b23849-018d-4250-af82-6ab5c4434837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# use the existing diff DataFrame as starting point\n",
    "diff_df = pd.read_csv('wo_diff_dev_prod_count_final_uniqueid.csv', index_col=0)\n",
    "\n",
    "# heatmap without cell annotations\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    diff_df,\n",
    "    fmt='',\n",
    "    cmap='YlOrRd',\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray',\n",
    "    square=True,\n",
    "    cbar_kws={'label': 'Missing Scenes Count'},\n",
    "    vmin=0,\n",
    "    # vmax=2\n",
    ")\n",
    "\n",
    "ax.set_title('WO: Prod - Dev', fontsize=14)\n",
    "ax.set_xlabel('Path')\n",
    "ax.set_ylabel('Row')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68362f4f-4185-4c1d-aa25-7be97e1510c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b4a25-b1c5-4e13-9c87-1243e0896c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696bc17a-7979-4fe3-b042-3bc17779f342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0282a4ec-8c16-4274-a0da-9f64efa838e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_fc = dc_dev.find_datasets(product='ga_ls_fc_3', time=time_range)\n",
    "prod_fc = dc_prod.find_datasets(product='ga_ls_fc_3', time=time_range)\n",
    "c = list(set(prod_fc) - set(dev_fc))\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51264f18-dd89-49ad-aefa-bb02332286b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for final maturity only\n",
    "final_dev_fc = [\n",
    "    ds\n",
    "    for ds in dev_fc\n",
    "    if ds.metadata_doc.get(\"properties\", {}).get(\"dea:dataset_maturity\") == \"final\"\n",
    "]\n",
    "\n",
    "# Count unique scene IDs by path and row\n",
    "fc_path_row_unique_ids = {}\n",
    "\n",
    "for ds in final_dev_fc:\n",
    "    props = ds.metadata_doc.get(\"properties\", {})\n",
    "    path = props.get(\"landsat:wrs_path\")\n",
    "    row = props.get(\"landsat:wrs_row\")\n",
    "    unique_id = ds.metadata_doc.get(\"id\")  # UUID as the unique identifier\n",
    "    if path is None or row is None or unique_id is None:\n",
    "        continue\n",
    "    key = (path, row)\n",
    "    if key not in fc_path_row_unique_ids:\n",
    "        fc_path_row_unique_ids[key] = set()\n",
    "    fc_path_row_unique_ids[key].add(unique_id)\n",
    "# Create DataFrame with counts\n",
    "df = pd.DataFrame(\n",
    "    [{\"path\": k[0], \"row\": k[1], \"count\": len(v)} for k, v in fc_path_row_unique_ids.items()]\n",
    ")\n",
    "\n",
    "pivot_df = df.pivot(index=\"row\", columns=\"path\", values=\"count\")\n",
    "\n",
    "# Reverse columns (if needed)\n",
    "pivot_df = pivot_df[pivot_df.columns[::-1]]\n",
    "\n",
    "# Clean up axis labels\n",
    "pivot_df.index.name = \"\"\n",
    "pivot_df.columns.name = \"\"\n",
    "\n",
    "# Export to CSV\n",
    "pivot_df.to_csv(\"fc_dev_count_final_uniqueid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e14b0f-adbf-42f2-9f3e-f1d939882c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for final maturity only\n",
    "final_prod_fc = [\n",
    "    ds\n",
    "    for ds in prod_fc\n",
    "    if ds.metadata_doc.get(\"properties\", {}).get(\"dea:dataset_maturity\") == \"final\"\n",
    "]\n",
    "\n",
    "# Count unique scene IDs by path and row\n",
    "fc_path_row_unique_ids = {}\n",
    "\n",
    "for ds in final_prod_fc:\n",
    "    props = ds.metadata_doc.get(\"properties\", {})\n",
    "    path = props.get(\"landsat:wrs_path\")\n",
    "    row = props.get(\"landsat:wrs_row\")\n",
    "    unique_id = ds.metadata_doc.get(\"id\")  # UUID as the unique identifier\n",
    "    if path is None or row is None or unique_id is None:\n",
    "        continue\n",
    "    key = (path, row)\n",
    "    if key not in fc_path_row_unique_ids:\n",
    "        fc_path_row_unique_ids[key] = set()\n",
    "    fc_path_row_unique_ids[key].add(unique_id)\n",
    "fc_path_row_unique_ids\n",
    "# Create DataFrame with counts\n",
    "df = pd.DataFrame(\n",
    "    [{\"path\": k[0], \"row\": k[1], \"count\": len(v)} for k, v in fc_path_row_unique_ids.items()]\n",
    ")\n",
    "\n",
    "pivot_df = df.pivot(index=\"row\", columns=\"path\", values=\"count\")\n",
    "\n",
    "# Reverse columns (if needed)\n",
    "pivot_df = pivot_df[pivot_df.columns[::-1]]\n",
    "\n",
    "# Clean up axis labels\n",
    "pivot_df.index.name = \"\"\n",
    "pivot_df.columns.name = \"\"\n",
    "\n",
    "# Export to CSV\n",
    "pivot_df.to_csv(\"fc_prod_count_final_uniqueid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3bf615-0950-4675-85c4-53cf993f7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_count = pd.read_csv('fc_prod_count_final_uniqueid.csv', index_col=0)\n",
    "dev_count = pd.read_csv('fc_dev_count_final_uniqueid.csv', index_col=0)\n",
    "\n",
    "# reduce to columns in common\n",
    "prod_count = prod_count[[c for c in prod_count.columns if c in dev_count.columns]]\n",
    "dev_count = dev_count[[c for c in prod_count.columns]]\n",
    "\n",
    "# reduce to same index \n",
    "common_index = prod_count.index.intersection(dev_count.index)\n",
    "prod_count = prod_count.loc[common_index]\n",
    "dev_count = dev_count.loc[common_index]\n",
    "\n",
    "# double check\n",
    "assert prod_count.columns.equals(dev_count.columns)\n",
    "assert prod_count.index.equals(dev_count.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcbfba-beb7-4180-aaad-c0b63372738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = prod_count - dev_count\n",
    "diff.to_csv('fc_diff_dev_prod_count_final_uniqueid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63151e7c-a5c9-4718-b184-11da771b88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# use the existing diff DataFrame as starting point\n",
    "diff_df = pd.read_csv('fc_diff_dev_prod_count_final_uniqueid.csv', index_col=0)\n",
    "\n",
    "# heatmap without cell annotations\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    diff_df,\n",
    "    fmt='',\n",
    "    cmap='YlOrRd',\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray',\n",
    "    square=True,\n",
    "    cbar_kws={'label': 'Missing Scenes Count'},\n",
    "    vmin=0,\n",
    "    # vmax=2\n",
    ")\n",
    "\n",
    "ax.set_title('FC: Prod - Dev', fontsize=14)\n",
    "ax.set_xlabel('Path')\n",
    "ax.set_ylabel('Row')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad7d9fe-23be-4ea9-a3a5-c94abadbf53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44719e-0bbe-4e7c-b61b-8224417c2720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00bb66c-969c-42f6-8571-d6a6c6ad2422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ce24b-2abe-4964-a44d-54f13d0abbed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10743d-18f3-4de2-b4dd-65df6b16e647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d804526-6b7d-4609-b7df-9fa1b0e66c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac00df8-a5d6-4cc6-b444-6b4d29c59ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397e80d-39be-4d88-9541-2c1e15ead99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc2dd2-a4c5-482b-8bde-168da77f7076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd22e6-6295-45e7-97c0-6867197ff689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f001d-06d1-4acd-8eff-1fa8acc55980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c2cb8e-ec40-4b67-9515-d7f58109c6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bcac43-a236-4e27-886d-7869585913ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e0935-42d0-4f0d-9fcf-3c8fe704c4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b56c3-5b69-4786-a1bb-be15bf15a878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09882128-cd0d-4c6e-9d04-bc1bed7dc2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5830e3f3-0b3a-4fa7-8313-3ad4d556e4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd4baa-e394-44e0-aa33-38268e403ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9740e5-a3e4-4555-9385-adaf441dc4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8dda8-cdc7-456a-8cba-c86eaef931c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41791f67-c53e-408e-948f-0ecdbd0e5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_final_titles(dataset_list):\n",
    "    titles = set()\n",
    "    for ds in dataset_list:\n",
    "        props = ds.metadata_doc.get(\"properties\", {})\n",
    "        if props.get(\"dea:dataset_maturity\") != \"final\":\n",
    "            continue\n",
    "        title = props.get(\"title\")\n",
    "        if title:\n",
    "            titles.add(title)\n",
    "    return titles\n",
    "\n",
    "dev_titles = extract_final_titles(dev_fc)\n",
    "prod_titles = extract_final_titles(prod_fc)\n",
    "\n",
    "missing_in_dev = sorted(prod_titles - dev_titles)\n",
    "missing_in_prod = sorted(dev_titles - prod_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2d106-cb96-4ef6-bf0b-b177b1997a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_in_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab1493-2829-430d-8313-38ebc2a40786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_missing_ids_all_path_rows(dev_fc, prod_fc):\n",
    "    def extract_ids_by_path_row(dataset_list):\n",
    "        ids_dict = defaultdict(set)\n",
    "        for ds in dataset_list:\n",
    "            props = ds.metadata_doc.get(\"properties\", {})\n",
    "            if props.get(\"dea:dataset_maturity\") != \"final\":\n",
    "                continue\n",
    "            path = props.get(\"landsat:wrs_path\")\n",
    "            row = props.get(\"landsat:wrs_row\")\n",
    "            if path is None or row is None:\n",
    "                continue\n",
    "            ids_dict[(path, row)].add(ds.id)\n",
    "        return ids_dict\n",
    "\n",
    "    dev_ids_by_path_row = extract_ids_by_path_row(dev_fc)\n",
    "    prod_ids_by_path_row = extract_ids_by_path_row(prod_fc)\n",
    "\n",
    "    all_keys = set(dev_ids_by_path_row.keys()) | set(prod_ids_by_path_row.keys())\n",
    "\n",
    "    missing_in_dev = {}\n",
    "    missing_in_prod = {}\n",
    "\n",
    "    for key in all_keys:\n",
    "        dev_ids = dev_ids_by_path_row.get(key, set())\n",
    "        prod_ids = prod_ids_by_path_row.get(key, set())\n",
    "\n",
    "        missing_dev = sorted(prod_ids - dev_ids)\n",
    "        missing_prod = sorted(dev_ids - prod_ids)\n",
    "\n",
    "        if missing_dev:\n",
    "            missing_in_dev[key] = missing_dev\n",
    "        if missing_prod:\n",
    "            missing_in_prod[key] = missing_prod\n",
    "\n",
    "    # Print summary\n",
    "    for (path, row), missing_ids in missing_in_dev.items():\n",
    "        print(f\"Missing in DEV for path={path}, row={row}:\")\n",
    "        for _id in missing_ids:\n",
    "            print(f\"  {_id}\")\n",
    "        print()\n",
    "\n",
    "    for (path, row), missing_ids in missing_in_prod.items():\n",
    "        print(f\"Missing in PROD for path={path}, row={row}:\")\n",
    "        for _id in missing_ids:\n",
    "            print(f\"  {_id}\")\n",
    "        print()\n",
    "\n",
    "    return missing_in_dev, missing_in_prod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71019787-0c75-48e5-868e-9592e3513e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dev, missing_prod = find_missing_ids_all_path_rows(dev_fc, prod_fc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34644e39-5ee1-4010-9d24-ebb7b0a3b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def find_missing_scenes_grouped(dev_fc, prod_fc):\n",
    "    # Helper to extract scene IDs grouped by path and row\n",
    "    def scenes_by_path_row(datasets):\n",
    "        d = {}\n",
    "        for ds in datasets:\n",
    "            props = ds.metadata_doc.get(\"properties\", {})\n",
    "            if props.get(\"dea:dataset_maturity\") != \"final\":\n",
    "                continue\n",
    "            p = props.get(\"landsat:wrs_path\")\n",
    "            r = props.get(\"landsat:wrs_row\")\n",
    "            sid = props.get(\"landsat:landsat_scene_id\") or props.get(\"title\")\n",
    "            if p is None or r is None or sid is None:\n",
    "                continue\n",
    "            d.setdefault((p, r), set()).add(sid)\n",
    "        return d\n",
    "\n",
    "    dev_scenes = scenes_by_path_row(dev_fc)\n",
    "    prod_scenes = scenes_by_path_row(prod_fc)\n",
    "\n",
    "    missing_in_dev = {}\n",
    "    missing_in_prod = {}\n",
    "\n",
    "    all_keys = set(dev_scenes.keys()).union(prod_scenes.keys())\n",
    "\n",
    "    for key in all_keys:\n",
    "        dev_set = dev_scenes.get(key, set())\n",
    "        prod_set = prod_scenes.get(key, set())\n",
    "\n",
    "        missing_dev = prod_set - dev_set\n",
    "        missing_prod = dev_set - prod_set\n",
    "\n",
    "        if missing_dev:\n",
    "            missing_in_dev[key] = list(missing_dev)\n",
    "        if missing_prod:\n",
    "            missing_in_prod[key] = list(missing_prod)\n",
    "\n",
    "    return missing_in_dev, missing_in_prod\n",
    "\n",
    "def prepare_heatmap_data(missing_in_dev, dev_fc, prod_fc):\n",
    "    # Collect all path/row combos from dev and prod datasets\n",
    "    def get_all_path_rows(datasets):\n",
    "        combos = set()\n",
    "        for ds in datasets:\n",
    "            props = ds.metadata_doc.get(\"properties\", {})\n",
    "            if props.get(\"dea:dataset_maturity\") != \"final\":\n",
    "                continue\n",
    "            p = props.get(\"landsat:wrs_path\")\n",
    "            r = props.get(\"landsat:wrs_row\")\n",
    "            if p is not None and r is not None:\n",
    "                combos.add((p, r))\n",
    "        return combos\n",
    "\n",
    "    dev_combos = get_all_path_rows(dev_fc)\n",
    "    prod_combos = get_all_path_rows(prod_fc)\n",
    "\n",
    "    all_combos = dev_combos.union(prod_combos)\n",
    "\n",
    "    # Extract unique paths and rows (sorted)\n",
    "    all_paths = sorted({p for p, r in all_combos})\n",
    "    all_rows = sorted({r for p, r in all_combos})\n",
    "\n",
    "    # Initialize DataFrame with NaNs for all combos\n",
    "    df_full = pd.DataFrame(np.nan, index=all_rows, columns=all_paths)\n",
    "\n",
    "    # Fill in zero for combos with data but no missing scenes\n",
    "    for (path, row) in all_combos:\n",
    "        df_full.at[row, path] = 0\n",
    "\n",
    "    # Overwrite with missing counts where applicable\n",
    "    for (path, row), missing_scenes in missing_in_dev.items():\n",
    "        df_full.at[row, path] = len(missing_scenes)\n",
    "\n",
    "    return df_full\n",
    "\n",
    "# Run missing scene detection\n",
    "missing_in_dev, missing_in_prod = find_missing_scenes_grouped(dev_fc, prod_fc)\n",
    "\n",
    "# Prepare full heatmap data including zero counts\n",
    "heatmap_data = prepare_heatmap_data(missing_in_dev, dev_fc, prod_fc)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    heatmap_data,\n",
    "    cmap='YlOrRd',\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray',\n",
    "    square=True,\n",
    "    cbar_kws={'label': 'Missing Scenes Count'},\n",
    "    vmin=0\n",
    ")\n",
    "\n",
    "ax.set_title('Count of Missing Scenes in DEV by Path and Row', fontsize=14)\n",
    "ax.set_xlabel('Path')\n",
    "ax.set_ylabel('Row')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c132e66-1781-4dac-ae0c-5b89411adfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_ids_by_path_row(dev_fc, prod_fc, target_path, target_row):\n",
    "    def extract_ids(datasets, path, row):\n",
    "        ids = set()\n",
    "        for ds in datasets:\n",
    "            props = ds.metadata_doc.get(\"properties\", {})\n",
    "            if props.get(\"dea:dataset_maturity\") != \"final\":\n",
    "                continue\n",
    "            try:\n",
    "                p = int(props.get(\"landsat:wrs_path\"))\n",
    "                r = int(props.get(\"landsat:wrs_row\"))\n",
    "            except (TypeError, ValueError):\n",
    "                continue\n",
    "            if p == path and r == row:\n",
    "                ids.add(ds.id)\n",
    "        return ids\n",
    "\n",
    "    dev_ids = extract_ids(dev_fc, target_path, target_row)\n",
    "    prod_ids = extract_ids(prod_fc, target_path, target_row)\n",
    "\n",
    "    missing_in_dev = sorted(prod_ids - dev_ids)\n",
    "    missing_in_prod = sorted(dev_ids - prod_ids)\n",
    "\n",
    "    print(f\"Missing IDs in DEV (present in PROD) for path={target_path}, row={target_row}:\")\n",
    "    for mid in missing_in_dev:\n",
    "        print(f\"  {mid}\")\n",
    "\n",
    "    print(f\"\\nMissing IDs in PROD (present in DEV) for path={target_path}, row={target_row}:\")\n",
    "    for mid in missing_in_prod:\n",
    "        print(f\"  {mid}\")\n",
    "\n",
    "    return missing_in_dev, missing_in_prod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ad61f-65da-469b-8f9d-1b2f69b6c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_dev, missing_in_prod = find_missing_ids_by_path_row(dev_fc, prod_fc,106, 78) #path, row\n",
    "missing_in_prod\n",
    "missing_in_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1b851-3eea-452d-b47a-9de1da22826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_dev, missing_in_prod = find_missing_ids_by_path_row(dev_wofs, prod_wofs, 99, 85) #path, row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3bc27-27dd-4638-aaa6-dd7478985c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e3ad5d-10a1-4c37-adb2-8c83116aaacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbca9e-f462-4a70-8de1-661e78d509d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095883d-5896-43f2-b28c-5b674fabcd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571318b5-da5e-4a8d-8cfa-b14d2ab6ae2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ddbcf3-a7b2-43a5-8689-3305002e3460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288a669c-2717-4da4-8427-1a932e42aef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ac28c-e09c-4d5e-8181-51f686b55ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea45f646-29af-44a6-8c4f-25aa69470324",
   "metadata": {},
   "source": [
    "# Example read metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa03f8-f7dd-43f6-ae6a-82e04ea0545f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ds = wofs[10]\n",
    "#print(json.dumps(ds.metadata_doc, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385f15f-6bea-47e2-8409-a1102f4fb4e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ds = ard_all[10]\n",
    "# print(json.dumps(ds.metadata_doc, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2911619-f381-4039-b641-21116740c959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
